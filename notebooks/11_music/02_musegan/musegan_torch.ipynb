{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ðŸŽ¶ Music Generation - MuseGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235cbd1-f136-411c-88d9-f69f270c0b96",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own MuseGAN model to generate music in the style of the Bach chorales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import grad\n",
    "from musegan_utils import notes_to_midi, draw_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "N_BARS = 2\n",
    "N_STEPS_PER_BAR = 16\n",
    "MAX_PITCH = 83\n",
    "N_PITCHES = MAX_PITCH + 1\n",
    "Z_DIM = 32\n",
    "N_TRACKS = 4  # é€šå¸¸ Bach Chorales æœ‰ 4 ä¸ªå£°éƒ¨\n",
    "\n",
    "CRITIC_STEPS = 5\n",
    "GP_WEIGHT = 10\n",
    "CRITIC_LR = 0.001\n",
    "GENERATOR_LR = 0.001\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "EPOCHS = 6000\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f5e63-e36a-4dc8-9f03-cb29c1fa5290",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10303bc9-1d3b-4fbe-a70a-eb1627ebdec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"/app/data/bach-chorales/Jsb16thSeparated.npz\")\n",
    "with np.load(file, allow_pickle=True) as f:\n",
    "    data = f[\"train\"]\n",
    "\n",
    "N_SONGS = len(data)\n",
    "print(f\"{N_SONGS} chorales in the dataset\")\n",
    "chorale = data[0]\n",
    "N_BEATS, N_TRACKS = chorale.shape\n",
    "print(f\"{N_BEATS, N_TRACKS} shape of chorale 0\")\n",
    "print(\"\\nChorale 0\")\n",
    "print(chorale[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81c0c2-58ab-4528-a813-dee601a3b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "two_bars = np.array([x[: (N_STEPS_PER_BAR * N_BARS)] for x in data])\n",
    "two_bars = np.array(np.nan_to_num(two_bars, nan=MAX_PITCH), dtype=int)\n",
    "two_bars = two_bars.reshape([N_SONGS, N_BARS, N_STEPS_PER_BAR, N_TRACKS])\n",
    "\n",
    "# è½¬ one-hotï¼Œå¹¶æ˜ å°„åˆ° -1/1\n",
    "data_binary = np.eye(N_PITCHES)[two_bars]\n",
    "data_binary[data_binary == 0] = -1\n",
    "data_binary = data_binary.transpose(0, 1, 2, 4, 3)  # [N, bars, steps, pitches, tracks]\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(data_binary, dtype=torch.float32))\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac7386-3226-4ef9-887d-78d599e0b7dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Build the GAN <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8750aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "\n",
    "def convt2d_block(in_channels, out_channels, kernel_size, stride, padding, activation=\"relu\", bn=True):\n",
    "    layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(out_channels, momentum=0.9))\n",
    "    if activation == \"relu\":\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == \"tanh\":\n",
    "        layers.append(nn.Tanh())\n",
    "    elif activation == \"leakyrelu\":\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb77d8e-92e1-410d-87b1-f8142807f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(Z_DIM, 1024, kernel_size=(2,1), stride=(1,1), padding=0),\n",
    "            nn.BatchNorm2d(1024, momentum=0.9),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, Z_DIM, kernel_size=(N_BARS-1,1), stride=(1,1), padding=0),\n",
    "            nn.BatchNorm2d(Z_DIM, momentum=0.9),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = z.view(z.size(0), Z_DIM, 1, 1)\n",
    "        x = self.net(x)\n",
    "        return x.view(z.size(0), N_BARS, Z_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0386b-96ed-4589-bdb3-d9220b745636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(Z_DIM*4, 1024),\n",
    "            nn.BatchNorm1d(1024, momentum=0.9),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            convt2d_block(512, 512, (2,1), (2,1), (0,0)),\n",
    "            convt2d_block(512, 256, (2,1), (2,1), (0,0)),\n",
    "            convt2d_block(256, 256, (2,1), (2,1), (0,0)),\n",
    "            convt2d_block(256, 256, (1,7), (1,7), (0,0)),\n",
    "            convt2d_block(256, 1, (1,12), (1,12), (0,0), activation=\"tanh\", bn=False)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), 512, 2, 1)\n",
    "        x = self.conv_blocks(x)\n",
    "        return x.view(x.size(0), 1, N_STEPS_PER_BAR, N_PITCHES, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4779bc1-8cfc-43fb-9fb3-1c521c3c9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temporal = TemporalNetwork()\n",
    "        self.bar_generators = nn.ModuleList([BarGenerator() for _ in range(N_TRACKS)])\n",
    "    def forward(self, chords, style, melody, groove):\n",
    "        chords_over_time = self.temporal(chords)  # [B, N_BARS, Z_DIM]\n",
    "        melody_over_time = []\n",
    "        for t in range(N_TRACKS):\n",
    "            melody_track = melody[:, t, :]\n",
    "            melody_over_time.append(self.temporal(melody_track))\n",
    "        bars_output = []\n",
    "        for b in range(N_BARS):\n",
    "            track_output = []\n",
    "            c = chords_over_time[:, b, :]\n",
    "            s = style\n",
    "            for t in range(N_TRACKS):\n",
    "                m = melody_over_time[t][:, b, :]\n",
    "                g = groove[:, t, :]\n",
    "                z_input = torch.cat([c, s, m, g], dim=1)\n",
    "                track_output.append(self.bar_generators[t](z_input))\n",
    "            bars_output.append(torch.cat(track_output, dim=-1))  # æ‹¼æŽ¥ track\n",
    "        generator_output = torch.cat(bars_output, dim=1)  # æ‹¼æŽ¥ bar\n",
    "        return generator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5b32b-7be3-440f-8f4d-6acb91587468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3d_block(N_TRACKS, 128, (2,1,1), (1,1,1), 0)\n",
    "        self.conv2 = conv3d_block(128, 128, (N_BARS-1,1,1), (1,1,1), 0)\n",
    "        self.conv3 = conv3d_block(128, 128, (1,1,12), (1,1,12), 0)\n",
    "        self.conv4 = conv3d_block(128, 128, (1,1,7), (1,1,7), 0)\n",
    "        self.conv5 = conv3d_block(128, 128, (1,2,1), (1,2,1), 0)\n",
    "        self.conv6 = conv3d_block(128, 128, (1,2,1), (1,2,1), 0)\n",
    "        self.conv7 = conv3d_block(128, 256, (1,4,1), (1,2,1), 0)\n",
    "        self.conv8 = conv3d_block(256, 512, (1,3,1), (1,2,1), 0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, 1024)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,4,1,2,3)  # [B, tracks, bars, steps, pitch] -> [B,C,D,H,W]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.leaky(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e79ac-d8cb-4000-bc9e-87ef25be4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuseGAN:\n",
    "    def __init__(self, generator, critic, latent_dim, critic_steps, gp_weight):\n",
    "        self.generator = generator.to(device)\n",
    "        self.critic = critic.to(device)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.critic_steps = critic_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.g_optimizer = optim.Adam(generator.parameters(), lr=GENERATOR_LR, betas=(ADAM_BETA_1, ADAM_BETA_2))\n",
    "        self.c_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR, betas=(ADAM_BETA_1, ADAM_BETA_2))\n",
    "    def gradient_penalty(self, real, fake):\n",
    "        alpha = torch.rand(real.size(0), 1, 1, 1, 1).to(device)\n",
    "        interpolated = (alpha * real + (1-alpha) * fake).requires_grad_(True)\n",
    "        pred = self.critic(interpolated)\n",
    "        grads = grad(pred.sum(), interpolated, create_graph=True)[0]\n",
    "        grads = grads.view(grads.size(0), -1)\n",
    "        gp = ((grads.norm(2, dim=1) - 1)**2).mean()\n",
    "        return gp\n",
    "    def train_step(self, real):\n",
    "        batch_size = real.size(0)\n",
    "        real = real.to(device)\n",
    "        # Train Critic\n",
    "        for _ in range(self.critic_steps):\n",
    "            chords = torch.randn(batch_size, Z_DIM).to(device)\n",
    "            style = torch.randn(batch_size, Z_DIM).to(device)\n",
    "            melody = torch.randn(batch_size, N_TRACKS, Z_DIM).to(device)\n",
    "            groove = torch.randn(batch_size, N_TRACKS, Z_DIM).to(device)\n",
    "            fake = self.generator(chords, style, melody, groove)\n",
    "            real_pred = self.critic(real)\n",
    "            fake_pred = self.critic(fake.detach())\n",
    "            c_loss = fake_pred.mean() - real_pred.mean() + self.gp_weight * self.gradient_penalty(real, fake)\n",
    "            self.c_optimizer.zero_grad()\n",
    "            c_loss.backward()\n",
    "            self.c_optimizer.step()\n",
    "        # Train Generator\n",
    "        chords = torch.randn(batch_size, Z_DIM).to(device)\n",
    "        style = torch.randn(batch_size, Z_DIM).to(device)\n",
    "        melody = torch.randn(batch_size, N_TRACKS, Z_DIM).to(device)\n",
    "        groove = torch.randn(batch_size, N_TRACKS, Z_DIM).to(device)\n",
    "        fake = self.generator(chords, style, melody, groove)\n",
    "        g_loss = -self.critic(fake).mean()\n",
    "        self.g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        return c_loss.item(), g_loss.item()\n",
    "    def generate(self, num_scores):\n",
    "        chords = torch.randn(num_scores, Z_DIM).to(device)\n",
    "        style = torch.randn(num_scores, Z_DIM).to(device)\n",
    "        melody = torch.randn(num_scores, N_TRACKS, Z_DIM).to(device)\n",
    "        groove = torch.randn(num_scores, N_TRACKS, Z_DIM).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated = self.generator(chords, style, melody, groove).cpu().numpy()\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97c9b3-e6a7-4ed5-a09c-6ba15a9ac30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MuseGAN\n",
    "generator = Generator()\n",
    "critic = Critic()\n",
    "musegan = MuseGAN(generator, critic, Z_DIM, CRITIC_STEPS, GP_WEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cf5a8-b6cc-4e88-9e1c-4efdc28b82c4",
   "metadata": {},
   "source": [
    "## 3. Train the MuseGAN <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe69ad5-371d-401b-94bd-8f6ddc8c97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    c_losses, g_losses = [], []\n",
    "    for batch in dataloader:\n",
    "        real_batch = batch[0]\n",
    "        c_loss, g_loss = musegan.train_step(real_batch)\n",
    "        c_losses.append(c_loss)\n",
    "        g_losses.append(g_loss)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - C Loss: {np.mean(c_losses):.4f}, G Loss: {np.mean(g_losses):.4f}\")\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        gen_music = musegan.generate(1)\n",
    "        notes_to_midi(gen_music, N_BARS, N_TRACKS, N_STEPS_PER_BAR, filename=f\"output_{epoch:04d}\")\n",
    "        draw_score(gen_music, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeebf4e-1fb1-4050-8a2b-479200bf7090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "num_scores = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93121b1-1073-4aa0-b798-7561171afe6d",
   "metadata": {},
   "source": [
    "## Changing Chord Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6195d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chord\n",
    "chords_noise = torch.randn(num_scores, Z_DIM)\n",
    "style_noise = torch.randn(num_scores, Z_DIM)\n",
    "melody_noise = torch.randn(num_scores, N_TRACKS, Z_DIM)\n",
    "groove_noise = torch.randn(num_scores, N_TRACKS, Z_DIM)\n",
    "generated_music = generator(chords_noise, style_noise, melody_noise, groove_noise).detach().cpu().numpy()\n",
    "draw_score(generated_music, 0)\n",
    "notes_to_midi(generated_music, N_BARS, N_TRACKS, N_STEPS_PER_BAR, filename=\"output_midi_chords_changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663aa28-71a4-4297-88d0-6e88e625827e",
   "metadata": {},
   "source": [
    "# Changing Style Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style\n",
    "style_noise2 = torch.randn(num_scores, Z_DIM)\n",
    "generated_music = generator(chords_noise, style_noise2, melody_noise, groove_noise).detach().cpu().numpy()\n",
    "draw_score(generated_music, 0)\n",
    "notes_to_midi(generated_music, N_BARS, N_TRACKS, N_STEPS_PER_BAR, filename=\"output_midi_style_changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375319d2-7e91-4f8a-80a5-cb473c9e5e2c",
   "metadata": {},
   "source": [
    "## Changing Melody Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melody\n",
    "melody_noise2 = melody_noise.clone()\n",
    "melody_noise2[:, 0, :] = torch.randn(num_scores, Z_DIM)\n",
    "generated_music = generator(chords_noise, style_noise, melody_noise2, groove_noise).detach().cpu().numpy()\n",
    "draw_score(generated_music, 0)\n",
    "notes_to_midi(generated_music, N_BARS, N_TRACKS, N_STEPS_PER_BAR, filename=\"output_midi_melody_changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a187e-fd3c-4922-90b5-5c0abd82d7f7",
   "metadata": {},
   "source": [
    "## Changing groove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60266b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groove\n",
    "groove_noise2 = groove_noise.clone()\n",
    "groove_noise2[:, -1, :] = torch.randn(num_scores, Z_DIM)\n",
    "generated_music = generator(chords_noise, style_noise, melody_noise, groove_noise2).detach().cpu().numpy()\n",
    "draw_score(generated_music, 0)\n",
    "notes_to_midi(generated_music, N_BARS, N_TRACKS, N_STEPS_PER_BAR, filename=\"output_midi_groove_changed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
