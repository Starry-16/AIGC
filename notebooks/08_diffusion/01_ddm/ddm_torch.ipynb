{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# üî• Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235cbd1-f136-411c-88d9-f69f270c0b96",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own diffusion model on the Oxford flowers dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacc8be-c1d2-4108-aa7c-7453dbc777a6",
   "metadata": {},
   "source": [
    "The code is adapted from the excellent ['Denoising Diffusion Implicit Models' tutorial](https://keras.io/examples/generative/ddim/) created by Andr√°s B√©res available on the Keras website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "DATASET_REPETITIONS = 5\n",
    "LOAD_MODEL = False\n",
    "\n",
    "NOISE_EMBEDDING_SIZE = 32\n",
    "PLOT_DIFFUSION_STEPS = 20\n",
    "\n",
    "# optimization\n",
    "EMA = 0.999\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f5e63-e36a-4dc8-9f03-cb29c1fa5290",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089c317-2d66-4631-81f8-1a8230635845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰ΩøÁî® ImageFolder Âä†ËΩΩËä±ÂçâÊï∞ÊçÆÈõÜÔºàËá™Ë°åÊõøÊç¢Ë∑ØÂæÑÔºâ\n",
    "transform = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=\"/app/data/pytorch-challange-flower-dataset/dataset\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53945d9-b7c5-49d0-a356-bcf1d1e1798b",
   "metadata": {},
   "source": [
    "### 1.1 Diffusion schedules <a name=\"diffusion_schedules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330083c0-642e-4745-b160-1938493152da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_diffusion_schedule(diffusion_times):\n",
    "    min_rate = 0.0001\n",
    "    max_rate = 0.02\n",
    "    betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    signal_rates = torch.sqrt(alpha_bars)\n",
    "    noise_rates = torch.sqrt(1 - alpha_bars)\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "def cosine_diffusion_schedule(diffusion_times):\n",
    "    signal_rates = torch.cos(diffusion_times * math.pi / 2)\n",
    "    noise_rates = torch.sin(diffusion_times * math.pi / 2)\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "def offset_cosine_diffusion_schedule(diffusion_times):\n",
    "    min_signal_rate = 0.02\n",
    "    max_signal_rate = 0.95\n",
    "    start_angle = torch.acos(torch.tensor(max_signal_rate))\n",
    "    end_angle = torch.acos(torch.tensor(min_signal_rate))\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "    signal_rates = torch.cos(diffusion_angles)\n",
    "    noise_rates = torch.sin(diffusion_angles)\n",
    "    return noise_rates, signal_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5f3c3-4797-4b58-b559-45589f59aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_steps = 1000\n",
    "diffusion_times = torch.linspace(0, 1, T_steps)\n",
    "linear_noise_rates, linear_signal_rates = linear_diffusion_schedule(diffusion_times)\n",
    "cosine_noise_rates, cosine_signal_rates = cosine_diffusion_schedule(diffusion_times)\n",
    "offset_cosine_noise_rates, offset_cosine_signal_rates = offset_cosine_diffusion_schedule(diffusion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b7b5a-c79c-4728-8778-10656541dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diffusion_times, linear_signal_rates**2, label=\"linear\")\n",
    "plt.plot(diffusion_times, cosine_signal_rates**2, label=\"cosine\")\n",
    "plt.plot(diffusion_times, offset_cosine_signal_rates**2, label=\"offset_cosine\")\n",
    "plt.xlabel(\"t/T\")\n",
    "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eac1df-3a74-4432-9d4d-0ccfbb5dc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(diffusion_times, linear_noise_rates**2, label=\"linear\")\n",
    "plt.plot(diffusion_times, cosine_noise_rates**2, label=\"cosine\")\n",
    "plt.plot(diffusion_times, offset_cosine_noise_rates**2, label=\"offset_cosine\")\n",
    "plt.xlabel(\"t/T\")\n",
    "plt.ylabel(r\"$1-\\bar{\\alpha_t}$ (noise)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19acdf72",
   "metadata": {},
   "source": [
    "# ## 2. Noise embedding (sinusoidal)<a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6395352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def sinusoidal_embedding(x, dim=NOISE_EMBEDDING_SIZE):\n",
    "    device = x.device if isinstance(x, torch.Tensor) else torch.device(\"cpu\")\n",
    "    half_dim = dim // 2\n",
    "    frequencies = torch.exp(torch.linspace(math.log(1.0), math.log(1000.0), half_dim, device=device))\n",
    "    angles = 2 * math.pi * frequencies * x\n",
    "    embeddings = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598d401-867d-450c-a3ba-6823bf309456",
   "metadata": {},
   "source": [
    "## 3. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711f6fb-6b43-4e79-9450-faef9f2afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm2d(channels, affine=False)\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.activation = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.conv1(self.norm(x)))\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, depth):\n",
    "        super().__init__()\n",
    "        layers_ = [ResidualBlock(in_ch) for _ in range(depth)]\n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x_down = self.pool(x)\n",
    "        return x_down, x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, depth):\n",
    "        super().__init__()\n",
    "        layers_ = [ResidualBlock(in_ch) for _ in range(depth)]\n",
    "        self.layers = nn.Sequential(*layers_)\n",
    "    def forward(self, x, skip):\n",
    "        x = nn.functional.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, base_ch=32):\n",
    "        super().__init__()\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, kernel_size=1)\n",
    "        self.down1 = DownBlock(base_ch, base_ch, 2)\n",
    "        self.down2 = DownBlock(base_ch, base_ch*2, 2)\n",
    "        self.down3 = DownBlock(base_ch*2, base_ch*3, 2)\n",
    "        self.mid1 = ResidualBlock(base_ch*3)\n",
    "        self.mid2 = ResidualBlock(base_ch*3)\n",
    "        self.up3 = UpBlock(base_ch*3*2, base_ch*3, 2)\n",
    "        self.up2 = UpBlock(base_ch*3*2, base_ch*2, 2)\n",
    "        self.up1 = UpBlock(base_ch*2*2, base_ch, 2)\n",
    "        self.final_conv = nn.Conv2d(base_ch, 3, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x, noise_emb):\n",
    "        x = self.init_conv(x)\n",
    "        # Concatenate noise embedding\n",
    "        noise_emb_up = noise_emb.expand(-1, -1, x.shape[2], x.shape[3])\n",
    "        x = torch.cat([x, noise_emb_up], dim=1)\n",
    "        # Down\n",
    "        x, skip1 = self.down1(x)\n",
    "        x, skip2 = self.down2(x)\n",
    "        x, skip3 = self.down3(x)\n",
    "        x = self.mid1(x)\n",
    "        x = self.mid2(x)\n",
    "        # Up\n",
    "        x = self.up3(x, skip3)\n",
    "        x = self.up2(x, skip2)\n",
    "        x = self.up1(x, skip1)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455e5d-2cc7-4d72-94e1-412a0f5e69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, unet, device=DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.unet = unet.to(device)\n",
    "        self.ema_unet = UNet()\n",
    "        self.ema_unet.load_state_dict(unet.state_dict())\n",
    "        self.ema_unet.to(device)\n",
    "        self.diffusion_schedule = offset_cosine_diffusion_schedule\n",
    "    \n",
    "    def denoise(self, x, noise_rates, signal_rates):\n",
    "        pred_noises = self.unet(x, noise_rates**2)\n",
    "        pred_images = (x - noise_rates * pred_noises) / signal_rates\n",
    "        return pred_noises, pred_images\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        current_images = initial_noise\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "        for step in range(diffusion_steps):\n",
    "            diffusion_times = torch.ones((current_images.size(0),1,1,1), device=self.device) - step * step_size\n",
    "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "            pred_noises, pred_images = self.denoise(current_images, noise_rates, signal_rates)\n",
    "            next_diffusion_times = diffusion_times - step_size\n",
    "            next_noise_rates, next_signal_rates = self.diffusion_schedule(next_diffusion_times)\n",
    "            current_images = next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
    "        return current_images\n",
    "    \n",
    "    def generate(self, num_images, diffusion_steps, initial_noise=None):\n",
    "        if initial_noise is None:\n",
    "            initial_noise = torch.randn((num_images, 3, IMAGE_SIZE, IMAGE_SIZE), device=self.device)\n",
    "        gen_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
    "        gen_images = torch.clamp(gen_images, 0.0, 1.0)\n",
    "        return gen_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15745f6-c453-4342-af50-cd4fbf4556f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unet = UNet()\n",
    "ddm = DiffusionModel(unet)\n",
    "optimizer = optim.AdamW(unet.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for batch, _ in tqdm(train_loader):\n",
    "        batch = batch.to(DEVICE)\n",
    "        noises = torch.randn_like(batch)\n",
    "        diffusion_times = torch.rand((batch.size(0),1,1,1), device=DEVICE)\n",
    "        noise_rates, signal_rates = offset_cosine_diffusion_schedule(diffusion_times)\n",
    "        noisy_images = signal_rates * batch + noise_rates * noises\n",
    "        pred_noises, _ = ddm.denoise(noisy_images, noise_rates, signal_rates)\n",
    "        loss = loss_fn(pred_noises, noises)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # EMA update\n",
    "        with torch.no_grad():\n",
    "            for p, ema_p in zip(unet.parameters(), ddm.ema_unet.parameters()):\n",
    "                ema_p.data.mul_(EMA).add_(p.data*(1-EMA))\n",
    "    print(f\"Epoch {epoch} loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76ac27",
   "metadata": {},
   "source": [
    "# ## 6. Sampling<a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410856",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm.generate(num_images=4, diffusion_steps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
