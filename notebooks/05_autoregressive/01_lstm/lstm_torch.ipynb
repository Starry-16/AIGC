{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ü•ô Âü∫‰∫éÈ£üË∞±Êï∞ÊçÆÁöÑ LSTM ÊñáÊú¨ÁîüÊàê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582",
   "metadata": {},
   "source": [
    "Êú¨ Notebook Â∞Ü‰∏ÄÊ≠•Ê≠•ÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî® **PyTorch** Âú®È£üË∞±Êï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉ‰∏Ä‰∏™ LSTMÔºåÂπ∂ÁîüÊàêÊñ∞ÁöÑËèúË∞±ÊñáÊú¨„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {},
   "source": [
    "## 1. Load the data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/app/data/epirecipes/full_format_recipes.json\") as f:\n",
    "    recipe_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ËøáÊª§Êó†ÊïàÊ†∑Êú¨ÔºåÂπ∂ÊãºÊé• title + directions\n",
    "filtered_data = [\n",
    "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "    for x in recipe_data\n",
    "    if x.get(\"title\") and x.get(\"directions\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_recipes = len(filtered_data)\n",
    "print(f\"{n_recipes} recipes loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = filtered_data[9]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1",
   "metadata": {},
   "source": [
    "## 2. ÊñáÊú¨tokenÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s.lower()\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = text_data[9]\n",
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda78bb",
   "metadata": {},
   "source": [
    "## 3.ÊûÑÂª∫ËØçË°®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ÂàÜËØç\n",
    "tokenized_texts = [x.split() for x in text_data]\n",
    "\n",
    "# ÁªüËÆ°ËØçÈ¢ë\n",
    "counter = Counter()\n",
    "for tokens in tokenized_texts:\n",
    "    counter.update(tokens)\n",
    "\n",
    "# ‰øùÁïôÊúÄÂ∏∏ËßÅÁöÑ VOCAB_SIZE ‰∏™ËØç\n",
    "vocab = [\"<pad>\", \"<unk>\"] + [w for w, _ in counter.most_common(VOCAB_SIZE - 2)]\n",
    "word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "index_to_word = {i: w for w, i in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êü•ÁúãÂâçÂá†‰∏™ token\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {index_to_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞ÜÊñáÊú¨ËΩ¨Êàê token idÔºåÂπ∂ËøõË°å padding / truncation\n",
    "def encode(tokens):\n",
    "    ids = [word_to_index.get(t, 1) for t in tokens]\n",
    "    if len(ids) >= MAX_LEN + 1:\n",
    "        return ids[: MAX_LEN + 1]\n",
    "    return ids + [0] * (MAX_LEN + 1 - len(ids))\n",
    "\n",
    "encoded_texts = [encode(t) for t in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÊòæÁ§∫Âêå‰∏Ä‰∏™Á§∫‰æãÁöÑ token id\n",
    "print(encoded_texts[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f7744",
   "metadata": {},
   "source": [
    "## 3. ÊûÑÂª∫ËÆ≠ÁªÉÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, encoded_texts):\n",
    "        self.data = encoded_texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.data[idx], dtype=torch.long)\n",
    "        x = seq[:-1]\n",
    "        y = seq[1:]\n",
    "        return x, y\n",
    "\n",
    "dataset = RecipeDataset(encoded_texts)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. ÊûÑÂª∫ LSTM Ê®°Âûã <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, N_UNITS).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    model.load_state_dict(torch.load(\"./models/lstm.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {},
   "source": [
    "## 5. Train the LSTM <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, model, index_to_word, word_to_index):\n",
    "        self.model = model\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / probs.sum()\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens=50, temperature=1.0):\n",
    "        self.model.eval()\n",
    "        tokens = [self.word_to_index.get(w, 1) for w in start_prompt.split()]\n",
    "        info = []\n",
    "\n",
    "        while len(tokens) < max_tokens and tokens[-1] != 0:\n",
    "            x = torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(x)\n",
    "            probs = F.softmax(logits[0, -1], dim=0).cpu().numpy()\n",
    "            token, p = self.sample_from(probs, temperature)\n",
    "            info.append({\"prompt\": start_prompt, \"word_probs\": p})\n",
    "            tokens.append(token)\n",
    "            start_prompt += \" \" + self.index_to_word[token]\n",
    "\n",
    "        print(f\"\\nÁîüÊàêÊñáÊú¨:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "text_generator = TextGenerator(model, index_to_word, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    text_generator.generate(\"recipe for\", max_tokens=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ‰øùÂ≠òÊ®°Âûã\n",
    "torch.save(model.state_dict(), \"./models/lstm.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
   "metadata": {},
   "source": [
    "## 6. Generate text using the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probs(info, vocab, top_k=5):\n",
    "    for i in info:\n",
    "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
    "        probs = i[\"word_probs\"]\n",
    "        idx = np.argsort(probs)[::-1][:top_k]\n",
    "        for j in idx:\n",
    "            print(f\"{vocab[j]}:\\t{np.round(100 * probs[j], 2)}%\")\n",
    "        print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for roasted vegetables | chop 1 /\",\n",
    "    max_tokens=10,\n",
    "    temperature=1.0\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df72866-b483-4489-8e26-d5e1466410fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\",\n",
    "    max_tokens=7,\n",
    "    temperature=0.2\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
